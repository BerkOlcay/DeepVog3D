{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e81957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.0.1\n",
      "Numpy version: 1.22.4\n",
      "Pytorch version: 1.13.0\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 8271a193229fe4437026185e218d5b06f7c8ce69\n",
      "MONAI __file__: E:\\Users\\BerkOlcay\\anaconda3\\envs\\DL\\lib\\site-packages\\monai\\__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.8\n",
      "Nibabel version: 4.0.2\n",
      "scikit-image version: 0.19.3\n",
      "Pillow version: 9.2.0\n",
      "Tensorboard version: 2.11.0\n",
      "gdown version: 4.6.0\n",
      "TorchVision version: 0.14.0\n",
      "tqdm version: 4.64.1\n",
      "lmdb version: 1.3.0\n",
      "psutil version: 5.9.4\n",
      "pandas version: 1.5.2\n",
      "einops version: 0.4.1\n",
      "transformers version: 4.24.0\n",
      "mlflow version: 1.30.0\n",
      "pynrrd version: 0.4.2\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "Device is cuda\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import tempfile\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import (\n",
    "    ITKReader,\n",
    "    NumpyReader,\n",
    ")\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureTyped,\n",
    "    Flipd,\n",
    "    Lambdad,\n",
    "    LoadImaged,\n",
    "    RandAdjustContrastd, #check whether necessary\n",
    "    RandFlipd,\n",
    "    RandAffined,\n",
    "    Resize,\n",
    "    Resized,\n",
    "    Rotate90d,\n",
    "    ScaleIntensity,\n",
    "    ScaleIntensityd,\n",
    "    ToNumpy,\n",
    "    ToTensor,\n",
    "    ToTensord,\n",
    ")\n",
    "from monai.utils import first\n",
    "\n",
    "from matplotlib import pylab as plt\n",
    "from skimage.io import imread\n",
    "\n",
    "import itk\n",
    "\n",
    "monai.config.print_config()\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device is\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a351235",
   "metadata": {},
   "source": [
    "# Load data to be classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed3e8845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.columns:\n",
      " ['fn_img', 'fn_qa_img', 'fn_annotation', 'fn_seg_maps', 'tag_dataset', 'fn_seg_maps_np']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn_img</th>\n",
       "      <th>fn_qa_img</th>\n",
       "      <th>fn_annotation</th>\n",
       "      <th>fn_seg_maps</th>\n",
       "      <th>tag_dataset</th>\n",
       "      <th>fn_seg_maps_np</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12451_ubiris2_C107_S1_I7_000000.tiff</td>\n",
       "      <td>12451_ubiris2_C107_S1_I7_000000_seg_qa.png</td>\n",
       "      <td>12451_ubiris2_C107_S1_I7_000000.txt</td>\n",
       "      <td>12451_ubiris2_C107_S1_I7_000000_seg_maps.pkl</td>\n",
       "      <td>ubiris2</td>\n",
       "      <td>12451_ubiris2_C107_S1_I7_000000_seg_maps.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12452_ubiris2_C133_S1_I4_000000.tiff</td>\n",
       "      <td>12452_ubiris2_C133_S1_I4_000000_seg_qa.png</td>\n",
       "      <td>12452_ubiris2_C133_S1_I4_000000.txt</td>\n",
       "      <td>12452_ubiris2_C133_S1_I4_000000_seg_maps.pkl</td>\n",
       "      <td>ubiris2</td>\n",
       "      <td>12452_ubiris2_C133_S1_I4_000000_seg_maps.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12453_ubiris2_C79_S2_I2_000000.tiff</td>\n",
       "      <td>12453_ubiris2_C79_S2_I2_000000_seg_qa.png</td>\n",
       "      <td>12453_ubiris2_C79_S2_I2_000000.txt</td>\n",
       "      <td>12453_ubiris2_C79_S2_I2_000000_seg_maps.pkl</td>\n",
       "      <td>ubiris2</td>\n",
       "      <td>12453_ubiris2_C79_S2_I2_000000_seg_maps.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12454_ubiris2_C390_S1_I15_000000.tiff</td>\n",
       "      <td>12454_ubiris2_C390_S1_I15_000000_seg_qa.png</td>\n",
       "      <td>12454_ubiris2_C390_S1_I15_000000.txt</td>\n",
       "      <td>12454_ubiris2_C390_S1_I15_000000_seg_maps.pkl</td>\n",
       "      <td>ubiris2</td>\n",
       "      <td>12454_ubiris2_C390_S1_I15_000000_seg_maps.pkl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12455_ubiris2_C85_S1_I1_000000.tiff</td>\n",
       "      <td>12455_ubiris2_C85_S1_I1_000000_seg_qa.png</td>\n",
       "      <td>12455_ubiris2_C85_S1_I1_000000.txt</td>\n",
       "      <td>12455_ubiris2_C85_S1_I1_000000_seg_maps.pkl</td>\n",
       "      <td>ubiris2</td>\n",
       "      <td>12455_ubiris2_C85_S1_I1_000000_seg_maps.pkl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  fn_img  \\\n",
       "0   12451_ubiris2_C107_S1_I7_000000.tiff   \n",
       "1   12452_ubiris2_C133_S1_I4_000000.tiff   \n",
       "2    12453_ubiris2_C79_S2_I2_000000.tiff   \n",
       "3  12454_ubiris2_C390_S1_I15_000000.tiff   \n",
       "4    12455_ubiris2_C85_S1_I1_000000.tiff   \n",
       "\n",
       "                                     fn_qa_img  \\\n",
       "0   12451_ubiris2_C107_S1_I7_000000_seg_qa.png   \n",
       "1   12452_ubiris2_C133_S1_I4_000000_seg_qa.png   \n",
       "2    12453_ubiris2_C79_S2_I2_000000_seg_qa.png   \n",
       "3  12454_ubiris2_C390_S1_I15_000000_seg_qa.png   \n",
       "4    12455_ubiris2_C85_S1_I1_000000_seg_qa.png   \n",
       "\n",
       "                          fn_annotation  \\\n",
       "0   12451_ubiris2_C107_S1_I7_000000.txt   \n",
       "1   12452_ubiris2_C133_S1_I4_000000.txt   \n",
       "2    12453_ubiris2_C79_S2_I2_000000.txt   \n",
       "3  12454_ubiris2_C390_S1_I15_000000.txt   \n",
       "4    12455_ubiris2_C85_S1_I1_000000.txt   \n",
       "\n",
       "                                     fn_seg_maps tag_dataset  \\\n",
       "0   12451_ubiris2_C107_S1_I7_000000_seg_maps.pkl     ubiris2   \n",
       "1   12452_ubiris2_C133_S1_I4_000000_seg_maps.pkl     ubiris2   \n",
       "2    12453_ubiris2_C79_S2_I2_000000_seg_maps.pkl     ubiris2   \n",
       "3  12454_ubiris2_C390_S1_I15_000000_seg_maps.pkl     ubiris2   \n",
       "4    12455_ubiris2_C85_S1_I1_000000_seg_maps.pkl     ubiris2   \n",
       "\n",
       "                                  fn_seg_maps_np  \n",
       "0   12451_ubiris2_C107_S1_I7_000000_seg_maps.pkl  \n",
       "1   12452_ubiris2_C133_S1_I4_000000_seg_maps.pkl  \n",
       "2    12453_ubiris2_C79_S2_I2_000000_seg_maps.pkl  \n",
       "3  12454_ubiris2_C390_S1_I15_000000_seg_maps.pkl  \n",
       "4    12455_ubiris2_C85_S1_I1_000000_seg_maps.pkl  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def draw_segmented_area(frame_rgb, pupil_map_masked, iris_map_masked, glints_map_masked, visible_map_masked, ax=None):\n",
    "    # Plot segmented area\n",
    "    #fig, ax = plt.subplots(figsize=(3.2,2.4))\n",
    "    alpha=0.4\n",
    "    fig_created = False\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=(6.4,4.8))\n",
    "        #canvas = FigureCanvas(fig)\n",
    "        ax = fig.subplots()\n",
    "        fig_created = True\n",
    "    ax.imshow(frame_rgb)#, vmax=1, vmin=0, cmap=\"gray\")\n",
    "    ax.imshow(np.ma.masked_where(visible_map_masked<0.5,visible_map_masked), cmap=\"spring\", vmax=1, vmin=0, alpha=alpha)\n",
    "    ax.imshow(np.ma.masked_where(iris_map_masked<0.5,iris_map_masked), cmap=\"GnBu\", vmax=1, vmin=0, alpha=alpha)\n",
    "    ax.imshow(np.ma.masked_where(pupil_map_masked<0.5,pupil_map_masked), cmap=\"OrRd\", vmax=1, vmin=0, alpha=alpha)\n",
    "    ax.imshow(np.ma.masked_where(glints_map_masked<0.5,glints_map_masked), cmap=\"cool\", vmax=1, vmin=0, alpha=alpha)\n",
    "    ax.axis('off')\n",
    "    if fig_created:\n",
    "        fig.tight_layout()\n",
    "        fig.canvas.draw()\n",
    "        plt.show()\n",
    "        \n",
    "def draw_segmented_areas_separately(frame_rgb, pupil_map_masked, iris_map_masked, glints_map_masked, visible_map_masked, ax=None):\n",
    "    # Plot segmented area\n",
    "    #fig, ax = plt.subplots(figsize=(3.2,2.4))\n",
    "    alpha=0.4\n",
    "    fig_created = False\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=(32, 24))\n",
    "        #canvas = FigureCanvas(fig)\n",
    "        ax = fig.subplots(1,4)\n",
    "        fig_created = True\n",
    "        \n",
    "    ax[0].imshow(frame_rgb)#, vmax=1, vmin=0, cmap=\"gray\")\n",
    "    ax[0].imshow(np.ma.masked_where(visible_map_masked<0.5,visible_map_masked), cmap=\"spring\", vmax=1, vmin=0)\n",
    "    ax[0].axis('off')\n",
    "    \n",
    "    ax[1].imshow(frame_rgb)#, vmax=1, vmin=0, cmap=\"gray\")\n",
    "    ax[1].imshow(np.ma.masked_where(iris_map_masked<0.5,iris_map_masked), cmap=\"GnBu\", vmax=1, vmin=0)\n",
    "    ax[1].axis('off')\n",
    "    \n",
    "    ax[2].imshow(frame_rgb)#, vmax=1, vmin=0, cmap=\"gray\")\n",
    "    ax[2].imshow(np.ma.masked_where(pupil_map_masked<0.5,pupil_map_masked), cmap=\"OrRd\", vmax=1, vmin=0)\n",
    "    ax[2].axis('off')\n",
    "    \n",
    "    ax[3].imshow(frame_rgb)#, vmax=1, vmin=0, cmap=\"gray\")\n",
    "    ax[3].imshow(np.ma.masked_where(glints_map_masked<0.5,glints_map_masked), cmap=\"cool\", vmax=1, vmin=0)\n",
    "    ax[3].axis('off')\n",
    "    if fig_created:\n",
    "        fig.tight_layout()\n",
    "        fig.canvas.draw()\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "pn_code = 'E:\\\\Users\\\\BerkOlcay\\\\DeepVOG3D\\\\DeepVOG3D\\\\PYTHON'\n",
    "pn_data = 'E:\\\\Users\\\\BerkOlcay\\\\DeepVOG3D\\\\DeepVOG3D\\\\data\\\\data_dv3d_monai_QA'\n",
    "pn_classifcation = 'E:\\\\Users\\\\BerkOlcay\\\\DeepVOG3D\\\\DeepVOG3D\\\\data\\\\data_dv3d_monai_QA\\\\pickle_open_close'\n",
    "\n",
    "df = pd.read_csv(os.path.join(pn_code,'df_dv3d_monai_files.csv'), index_col=0)\n",
    "df['fn_seg_maps_np'] = [s.replace('.pkl','.pkl') for s in df.fn_seg_maps]\n",
    "\n",
    "# set up dataset splits and dict-lists\n",
    "check_idxs = np.arange(0,df.shape[0])\n",
    "\n",
    "check_files = [{\"img\": os.path.join(pn_data, fn_img), \"seg\": os.path.join(pn_data, fn_seg)} for fn_img, fn_seg in zip(df.fn_img[check_idxs], df.fn_seg_maps_np[check_idxs])]\n",
    "\n",
    "print(f'df.columns:\\n {df.columns.tolist()}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b622c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms for image and segmentation\n",
    "img_size = np.array([240,320])\n",
    "rot_max = 45*np.pi/180.0\n",
    "shear_max = 0.5\n",
    "trans_max = tuple((img_size*0.15).astype(int))\n",
    "scale_max = 0.25\n",
    "\n",
    "def gray2rgb(x):\n",
    "    #print(x.shape)\n",
    "    if x.shape[0]==1:\n",
    "        x = x.repeat(3, 1, 1)\n",
    "        x.meta['original_channel_dim'] = -1 # THIS is the important line! \n",
    "    #print(x.shape)\n",
    "    return x\n",
    "\n",
    "def clean_tiff_meta(x):\n",
    "    for key in ['DocumentName', 'ImageDescription', 'Software']:\n",
    "        if key in x.meta.keys():\n",
    "            del x.meta[key]\n",
    "    return x\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        #Lambdad(keys=['img', 'seg'], func=lambda x: print(x), overwrite = False),\n",
    "        LoadImaged(keys=[\"img\"], reader= ITKReader, image_only = True),\n",
    "        LoadImaged(keys=[\"seg\"], reader=NumpyReader, image_only = True),\n",
    "        EnsureChannelFirstd(keys=[\"img\"]),\n",
    "        Lambdad(keys=['img'], func=lambda x: gray2rgb(x)), # gray to rgb conversion\n",
    "        ScaleIntensityd(keys=\"img\"),        \n",
    "        Flipd(keys=[\"seg\"], spatial_axis=[1]), # necessary due to various readers ITKReader and NumpyReader\n",
    "        Rotate90d(keys=[\"seg\"]), # necessary due to various readers ITKReader and NumpyReader\n",
    "        Rotate90d(keys=[\"img\", \"seg\"]), # necessary due to various readers ITKReader and NumpyReader\n",
    "        Rotate90d(keys=[\"img\", \"seg\"]), # necessary due to various readers ITKReader and NumpyReader\n",
    "        Rotate90d(keys=[\"img\", \"seg\"]), # necessary due to various readers ITKReader and NumpyReader\n",
    "        Resized(keys=[\"img\", \"seg\"], spatial_size=(240,320)),\n",
    "        RandAdjustContrastd(keys=[\"seg\"], prob=1.0, gamma=(0.1, 10.0)),\n",
    "        EnsureTyped(keys=\"img\"),\n",
    "        Lambdad(keys=['img'], func=lambda x: clean_tiff_meta(x)), # clean weird keys in TIFF metadata - turns out this is not necessary\n",
    "        ToTensord(keys=[\"img\", \"seg\"]),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af924e1f",
   "metadata": {},
   "source": [
    "# classify images and check whether segmentations are correct in the meanwhile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a2755b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add them to dataset, and data loader\n",
    "npc = ToNumpy()\n",
    "check_batch_size = 5506\n",
    "check_ds = monai.data.Dataset(data=check_files, transform=train_transforms)\n",
    "check_loader = DataLoader(\n",
    "    check_ds, \n",
    "    batch_size=check_batch_size, \n",
    "    shuffle=False,\n",
    "    num_workers=0)\n",
    "check_data = first(check_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb1aadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# related to segmentation check \n",
    "checkSegmentations = []\n",
    "extremeCases = []\n",
    "notPrecise = []\n",
    "\n",
    "# if there are pickles, load them and resume to check\n",
    "pn_checkSegmentationsPkl = os.path.join(pn_code, \"checkSegmentations.pkl\")\n",
    "pn_extremeCasesPkl = os.path.join(pn_code, \"extremeCases.pkl\")\n",
    "pn_notPrecisePkl = os.path.join(pn_code, \"notPrecise.pkl\")\n",
    "\n",
    "if os.path.isfile(pn_checkSegmentationsPkl):\n",
    "    checkSegmentations = pickle.load( open(pn_checkSegmentationsPkl, \"rb\" ))\n",
    "if os.path.isfile(pn_extremeCasesPkl):\n",
    "    extremeCases = pickle.load( open(pn_extremeCasesPkl, \"rb\" ))\n",
    "if os.path.isfile(pn_notPrecisePkl):\n",
    "    extremeCases = pickle.load( open(pn_notPrecisePkl, \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01077dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 273169.59 sec for 20 images\n"
     ]
    }
   ],
   "source": [
    "# classify images whether the eye is open or closed\n",
    "# also control segmentations whether they're correct\n",
    "filename = \"\"\n",
    "index = 0\n",
    "while index < check_batch_size:\n",
    "    img_cf = np.squeeze(npc(check_data[\"img\"])[index,:,:,:])\n",
    "    seg_cf = np.squeeze(npc(check_data[\"seg\"])[index,:,:,:])\n",
    "    \n",
    "    # channel last versions for plotting\n",
    "    pupil_map_masked, iris_map_masked, visible_map_masked, glints_map_masked = tuple([np.squeeze(seg_cf[c,:,:]) for c in [0,1,2,3]])\n",
    "    img = np.moveaxis(img_cf, [0,1,2], [-1,-3,-2])\n",
    "    draw_segmented_areas_separately(img, pupil_map_masked, iris_map_masked, glints_map_masked, visible_map_masked)\n",
    "    draw_segmented_area(img, pupil_map_masked, iris_map_masked, glints_map_masked, visible_map_masked)\n",
    "    \n",
    "    previousFilename = filename\n",
    "    filename = check_files[index][\"img\"]\n",
    "    changed_folder = filename.replace('\\data_dv3d_monai_QA','\\data_dv3d_monai_QA\\pickle_open_close')\n",
    "    without_extension = os.path.splitext(changed_folder)[0]\n",
    "    new_filename = without_extension +'_classification.pkl'\n",
    "    print (\"image index \", index, \": \", filename.split('\\\\')[-1])\n",
    "    \n",
    "    a = -1\n",
    "    while (a not in range(7)):\n",
    "        print(\"Enter a number\")\n",
    "        print(\"0 go back\")\n",
    "        print(\"1 open\")\n",
    "        print(\"2 open not precise\")\n",
    "        print(\"3 open, check segmentation\")\n",
    "        print(\"4 open, extreme cases\")\n",
    "        print(\"5 close\")\n",
    "        print(\"6 close, check segmentation\")\n",
    "        a = int(input(\"Enter a number: \"))\n",
    "        if (a == 0 and index != 0): \n",
    "            index = index - 2\n",
    "            if (previousFilename in checkSegmentations):\n",
    "                checkSegmentations.remove(previousFilename)\n",
    "            if (previousFilename in extremeCases):\n",
    "                extremeCases.remove(previousFilename)\n",
    "            if (previousFilename in notPrecise):\n",
    "                notPrecise.remove(previousFilename)\n",
    "        elif (a == 1):\n",
    "            ylabel = np.ones(1)\n",
    "        elif (a == 2): \n",
    "            ylabel = np.ones(1)\n",
    "            notPrecise.append(filename)\n",
    "        elif (a == 3):\n",
    "            ylabel = np.ones(1)\n",
    "            checkSegmentations.append(filename)\n",
    "        elif (a == 4):\n",
    "            ylabel = np.ones(1)\n",
    "            extremeCases.append(filename)\n",
    "        elif (a == 5):\n",
    "            ylabel = np.zeros(1)\n",
    "        elif (a == 6):\n",
    "            ylabel = np.zeros(1)\n",
    "            checkSegmentations.append(filename)\n",
    "        else:\n",
    "            print (\"Wrong input. Enter a number\")\n",
    "            print(\"0 go back\")\n",
    "            print(\"1 open\")\n",
    "            print(\"2 open not precise\")\n",
    "            print(\"3 open, check segmentation\")\n",
    "            print(\"4 open, extreme cases\")\n",
    "            print(\"5 close\")\n",
    "            print(\"6 close, check segmentation\")\n",
    "        \n",
    "    fileObject = open(new_filename, 'wb')\n",
    "    pickle.dump(ylabel, fileObject)\n",
    "    fileObject.close()\n",
    "    print(new_filename, \" updated.\")\n",
    "    \n",
    "    clear_output(wait=False)\n",
    "    index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "03360564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update excel table for the classifications\n",
    "def convertFromImgToClassification(imgName):\n",
    "    without_extension = os.path.splitext(imgName)[0]\n",
    "    classification_filename = without_extension +'_classification.pkl'\n",
    "    target_file = os.path.join(\"pickle_open_close\", classification_filename)\n",
    "    return target_file\n",
    "\n",
    "dff = pd.read_csv(os.path.join(pn_code,'df_dv3d_oc_monai_files.csv'), index_col=0)\n",
    "dff['fn_cls'] = [convertFromImgToClassification(s) for s in df.fn_seg_maps]\n",
    "dff.to_csv('df_dv3d_oc_monai_files.csv', index= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf238d7",
   "metadata": {},
   "source": [
    "# print sizes of the arrays and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "31938463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkSegmentations  178\n",
      "extremeCases  139\n",
      "notPrecise  154\n"
     ]
    }
   ],
   "source": [
    "print('checkSegmentations ', len(checkSegmentations))\n",
    "#print(checkSegmentations)\n",
    "print('extremeCases ', len(extremeCases))\n",
    "#print(extremeCases)\n",
    "print('notPrecise ', len(notPrecise))\n",
    "#print(notPrecise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9ada31d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Users\\BerkOlcay\\DeepVOG3D\\DeepVOG3D\\PYTHON\\checkSegmentations.pkl  saved.\n",
      "E:\\Users\\BerkOlcay\\DeepVOG3D\\DeepVOG3D\\PYTHON\\extremeCases.pkl  saved.\n",
      "E:\\Users\\BerkOlcay\\DeepVOG3D\\DeepVOG3D\\PYTHON\\notPrecise.pkl  saved.\n"
     ]
    }
   ],
   "source": [
    "# save checkSegmentations\n",
    "fileObject = open(pn_checkSegmentationsPkl, 'wb')\n",
    "pickle.dump(checkSegmentations, fileObject)\n",
    "fileObject.close()\n",
    "print(pn_checkSegmentationsPkl, \" saved.\")\n",
    "\n",
    "# save extremeCases\n",
    "fileObject = open(pn_extremeCasesPkl, 'wb')\n",
    "pickle.dump(extremeCases, fileObject)\n",
    "fileObject.close()\n",
    "print(pn_extremeCasesPkl, \" saved.\")\n",
    "\n",
    "# save checkSegmentations\n",
    "fileObject = open(pn_notPrecisePkl, 'wb')\n",
    "pickle.dump(notPrecise, fileObject)\n",
    "fileObject.close()\n",
    "print(pn_notPrecisePkl, \" saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3818015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove 05464_dsgz3_P32_R.mp4_112078.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff319171",
   "metadata": {},
   "source": [
    "# double check the arrays (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df6ad9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkSegmentationsFiles = []\n",
    "for file in check_files:\n",
    "    if (file['img'] in checkSegmentations):\n",
    "        checkSegmentationsFiles.append(file)\n",
    "print(checkSegmentationsFiles[:3])\n",
    "print(len(checkSegmentationsFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b959c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_batch_size = 368\n",
    "check_ds = monai.data.Dataset(data=checkSegmentationsFiles, transform=train_transforms)\n",
    "check_loader = DataLoader(\n",
    "    check_ds, \n",
    "    batch_size=check_batch_size, \n",
    "    shuffle=False,\n",
    "    num_workers=0)\n",
    "check_data = first(check_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548af935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index = 0\n",
    "while index < check_batch_size:\n",
    "    img_cf = np.squeeze(npc(check_data[\"img\"])[index,:,:,:])\n",
    "    seg_cf = np.squeeze(npc(check_data[\"seg\"])[index,:,:,:])\n",
    "    \n",
    "    # channel last versions for plotting\n",
    "    pupil_map_masked, iris_map_masked, visible_map_masked, glints_map_masked = tuple([np.squeeze(seg_cf[c,:,:]) for c in [0,1,2,3]])\n",
    "    img = np.moveaxis(img_cf, [0,1,2], [-1,-3,-2])\n",
    "    draw_segmented_areas_separately(img, pupil_map_masked, iris_map_masked, glints_map_masked, visible_map_masked)\n",
    "    draw_segmented_area(img, pupil_map_masked, iris_map_masked, glints_map_masked, visible_map_masked)\n",
    "    \n",
    "    filename = checkSegmentationsFiles[index][\"img\"]\n",
    "    print (\"image index \", index, \": \", filename.split('\\\\')[-1])\n",
    "    \n",
    "    a = int(input(\"Enter a number: \"))\n",
    "    if (a == 2):\n",
    "        checkSegmentations.remove(filename)\n",
    "        \n",
    "    clear_output(wait=False)\n",
    "    index = index + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4b09517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(len(checkSegmentations))\n",
    "print (filename in checkSegmentations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee35cff",
   "metadata": {},
   "source": [
    "# copy the images and segmentation comprasions to another folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "59cdb64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkSegmentations  178\n"
     ]
    }
   ],
   "source": [
    "print('checkSegmentations ', len(notPrecise))\n",
    "pn_targetFile = os.path.join(pn_data,'1check_segmentations\\\\')\n",
    "\n",
    "for file_name in checkSegmentations:\n",
    "    without_extension = os.path.splitext(file_name)[0]\n",
    "    seg_qa_file_name = without_extension +'_seg_qa.png'\n",
    "    \n",
    "    shutil.copy(file_name, file_name.replace(pn_data,pn_targetFile))\n",
    "    shutil.copy(seg_qa_file_name, seg_qa_file_name.replace(pn_data,pn_targetFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b639fbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkSegmentations  154\n"
     ]
    }
   ],
   "source": [
    "print('checkSegmentations ', len(notPrecise))\n",
    "pn_targetFile = os.path.join(pn_data,'2not_precise\\\\')\n",
    "\n",
    "for file_name in notPrecise:\n",
    "    without_extension = os.path.splitext(file_name)[0]\n",
    "    seg_qa_file_name = without_extension +'_seg_qa.png'\n",
    "    \n",
    "    shutil.copy(file_name, file_name.replace(pn_data,pn_targetFile))\n",
    "    shutil.copy(seg_qa_file_name, seg_qa_file_name.replace(pn_data,pn_targetFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ab725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('checkSegmentations ', len(extremeCases))\n",
    "pn_targetFile = os.path.join(pn_data,'3extreme_cases\\\\')\n",
    "\n",
    "for file_name in extremeCases:\n",
    "    without_extension = os.path.splitext(file_name)[0]\n",
    "    seg_qa_file_name = without_extension +'_seg_qa.png'\n",
    "    \n",
    "    shutil.copy(file_name, file_name.replace(pn_data,pn_targetFile))\n",
    "    shutil.copy(seg_qa_file_name, seg_qa_file_name.replace(pn_data,pn_targetFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3664c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f3d411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
